#!/bin/bash

# é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# ä½¿ç”¨æ–¹æ³•: ./detector.sh [TARGET_DIR]

set -euo pipefail

# è¨­å®š
PARTIAL_READ_SIZE=${PARTIAL_READ_SIZE:-1048576}  # 1MB
TARGET_DIR="${1:-.}"
TEMP_DIR="/tmp/duplicate_detector_$$"

# åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ã‚’æ¤œå‡º
detect_hash_command() {
    if command -v sha256sum >/dev/null 2>&1; then
        HASH_CMD="sha256sum"
    elif command -v md5sum >/dev/null 2>&1; then
        HASH_CMD="md5sum"
    else
        echo "Error: sha256sum ã‚‚ md5sum ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“" >&2
        exit 1
    fi
}

# ä½¿ç”¨æ–¹æ³•
usage() {
    cat << 'EOF'
ä½¿ç”¨æ–¹æ³•: ./detector.sh [TARGET_DIR]

é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºãƒ»å‰Šé™¤å€™è£œæç¤ºãƒ„ãƒ¼ãƒ«

å¼•æ•°:
    TARGET_DIR    æ¤œç´¢å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰

ç’°å¢ƒå¤‰æ•°:
    PARTIAL_READ_SIZE    éƒ¨åˆ†ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1MB = 1048576ï¼‰

ä¾‹:
    ./detector.sh /home/user/Documents
    PARTIAL_READ_SIZE=2097152 ./detector.sh /var/data

å‡ºåŠ›: ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—ã¨å‰Šé™¤å€™è£œã‚’è¡¨ç¤º

GitHubã‹ã‚‰ç›´æ¥å®Ÿè¡Œ:
    curl -sSL https://raw.githubusercontent.com/user/repo/main/detector.sh | bash -s -- /path/to/dir
EOF
}

# ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
setup_temp() {
    mkdir -p "$TEMP_DIR"
    trap "rm -rf '$TEMP_DIR'" EXIT INT TERM
}

# éƒ¨åˆ†ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
calculate_partial_hash() {
    local filepath="$1"
    if [[ -r "$filepath" ]]; then
        head -c "$PARTIAL_READ_SIZE" "$filepath" 2>/dev/null | $HASH_CMD | cut -d' ' -f1
    fi
}

# å…¨ä½“ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
calculate_full_hash() {
    local filepath="$1"
    if [[ -r "$filepath" ]]; then
        $HASH_CMD "$filepath" 2>/dev/null | cut -d' ' -f1
    fi
}

# ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’äººé–“ãŒèª­ã‚ã‚‹å½¢å¼ã«å¤‰æ›
format_size() {
    local size="$1"
    if command -v numfmt >/dev/null 2>&1; then
        numfmt --to=iec --suffix=B "$size" 2>/dev/null || echo "${size} bytes"
    else
        echo "${size} bytes"
    fi
}

format_date() {
    local timestamp="$1"
    date -d "@$timestamp" "+%Y-%m-%d %H:%M:%S" 2>/dev/null || \
    date -r "$timestamp" "+%Y-%m-%d %H:%M:%S" 2>/dev/null || \
    echo "ä¸æ˜"
}

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
main() {
    if [[ "${1:-}" == "-h" || "${1:-}" == "--help" ]]; then
        usage
        exit 0
    fi
    
    if [[ ! -d "$TARGET_DIR" ]]; then
        echo "âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: '$TARGET_DIR'" >&2
        exit 1
    fi
    
    detect_hash_command
    setup_temp
    
    echo "ğŸš€ é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºé–‹å§‹" >&2
    echo "ğŸ“‚ å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: $TARGET_DIR" >&2
    echo "ğŸ” ãƒãƒƒã‚·ãƒ¥ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : $HASH_CMD" >&2
    echo "ğŸ“ éƒ¨åˆ†èª­ã¿è¾¼ã¿ã‚µã‚¤ã‚º: $(format_size $PARTIAL_READ_SIZE)" >&2
    echo "" >&2
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ•ã‚¡ã‚¤ãƒ«åé›†ãƒ»ã‚µã‚¤ã‚ºè¨ˆç®—
    echo "ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«åé›†ä¸­..." >&2
    find "$TARGET_DIR" -type f -exec stat -c '%s %Y %n' {} \; 2>/dev/null | \
        sort -n > "$TEMP_DIR/file_list" || {
        # macOSå¯¾å¿œ
        find "$TARGET_DIR" -type f -exec stat -f '%z %m %N' {} \; 2>/dev/null | \
            sort -n > "$TEMP_DIR/file_list"
    }
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚µã‚¤ã‚ºé‡è¤‡ãƒã‚§ãƒƒã‚¯
    echo "ğŸ“Š ã‚µã‚¤ã‚ºé‡è¤‡ãƒã‚§ãƒƒã‚¯ä¸­..." >&2
    awk '{size[$1]++; files[$1] = files[$1] $0 "\n"} 
         END {for(s in size) if(size[s]>1) print files[s]}' \
        "$TEMP_DIR/file_list" > "$TEMP_DIR/size_duplicates"
    
    if [[ ! -s "$TEMP_DIR/size_duplicates" ]]; then
        echo "" >&2
        echo "âœ… æ¤œå‡ºå®Œäº†" >&2
        echo ""
        echo "âœ¨ é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        return
    fi
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: éƒ¨åˆ†ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
    echo "ğŸ” éƒ¨åˆ†ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ä¸­..." >&2
    while read -r line; do
        [[ -n "$line" ]] || continue
        read -r size mtime filepath <<< "$line"
        
        if [[ -r "$filepath" ]]; then
            local partial_hash
            if partial_hash=$(calculate_partial_hash "$filepath"); then
                echo "$size $partial_hash $mtime $filepath" >> "$TEMP_DIR/partial_hashes"
            fi
        fi
    done < "$TEMP_DIR/size_duplicates"
    
    # éƒ¨åˆ†ãƒãƒƒã‚·ãƒ¥ã§ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°
    sort "$TEMP_DIR/partial_hashes" | \
        awk '{key=$1"_"$2; count[key]++; data[key] = data[key] $0 "\n"} 
             END {for(k in count) if(count[k]>1) print data[k]}' > "$TEMP_DIR/partial_groups"
    
    if [[ ! -s "$TEMP_DIR/partial_groups" ]]; then
        echo "" >&2
        echo "âœ… æ¤œå‡ºå®Œäº†" >&2
        echo ""
        echo "âœ¨ é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        return
    fi
    
    # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ•ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
    echo "ğŸ¯ ãƒ•ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ä¸­..." >&2
    while read -r line; do
        [[ -n "$line" ]] || continue
        read -r size partial_hash mtime filepath <<< "$line"
        
        if [[ -r "$filepath" ]]; then
            local full_hash
            if full_hash=$(calculate_full_hash "$filepath"); then
                echo "$full_hash $size $mtime $filepath" >> "$TEMP_DIR/full_hashes"
            fi
        fi
    done < "$TEMP_DIR/partial_groups"
    
    # ãƒ•ãƒ«ãƒãƒƒã‚·ãƒ¥ã§ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°
    sort "$TEMP_DIR/full_hashes" | \
        awk '{count[$1]++; data[$1] = data[$1] $0 "\n"} 
             END {for(h in count) if(count[h]>1) print data[h]}' > "$TEMP_DIR/final_groups"
    
    # ã‚¹ãƒ†ãƒƒãƒ—5: çµæœå‡ºåŠ›
    echo "ğŸ“‹ çµæœç”Ÿæˆä¸­..." >&2
    
    local group_count=0
    local total_duplicates=0
    local total_waste=0
    
    while read -r group_data; do
        [[ -n "$group_data" ]] || continue
        
        local files=()
        local mtimes=()
        local hash=""
        local size=0
        
        # ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
        while read -r line; do
            [[ -n "$line" ]] || continue
            read -r file_hash file_size mtime filepath <<< "$line"
            
            files+=("$filepath")
            mtimes+=("$mtime")
            
            if [[ -z "$hash" ]]; then
                hash="$file_hash"
                size="$file_size"
            fi
        done <<< "$group_data"
        
        # 2ã¤ä»¥ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã®ã¿å‡¦ç†
        if [[ ${#files[@]} -gt 1 ]]; then
            ((group_count++))
            total_duplicates=$((total_duplicates + ${#files[@]} - 1))
            total_waste=$((total_waste + size * (${#files[@]} - 1)))
            
            # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
            local newest_idx=0
            local newest_mtime="${mtimes[0]}"
            
            for ((i=1; i<${#mtimes[@]}; i++)); do
                if [[ "${mtimes[i]}" > "$newest_mtime" ]]; then
                    newest_mtime="${mtimes[i]}"
                    newest_idx=$i
                fi
            done
            
            echo ""
            echo "â”â”â” é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ— $group_count â”â”â”"
            echo "ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: $(format_size $size)"
            echo "ãƒãƒƒã‚·ãƒ¥: $hash"
            echo ""
            
            echo "ğŸ“‚ é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:"
            for ((i=0; i<${#files[@]}; i++)); do
                local date_str
                date_str=$(format_date "${mtimes[i]}")
                
                if [[ $i -eq $newest_idx ]]; then
                    echo "  âœ… [ä¿æŒ] ${files[i]} ($date_str)"
                else
                    echo "  âŒ [å‰Šé™¤å€™è£œ] ${files[i]} ($date_str)"
                fi
            done
            
            echo ""
            echo "ğŸ—‘ï¸  å‰Šé™¤ã‚³ãƒãƒ³ãƒ‰ä¾‹:"
            for ((i=0; i<${#files[@]}; i++)); do
                if [[ $i -ne $newest_idx ]]; then
                    echo "rm \"${files[i]}\""
                fi
            done
        fi
    done < <(awk 'BEGIN{RS="\n\n"} NF>0' "$TEMP_DIR/final_groups")
    
    echo ""
    echo "ğŸ“Š æ¤œå‡ºçµæœã‚µãƒãƒªãƒ¼:"
    echo "  é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—æ•°: $group_count"
    echo "  å‰Šé™¤å¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«æ•°: $total_duplicates"
    echo "  ç¯€ç´„å¯èƒ½å®¹é‡: $(format_size $total_waste)"
    
    echo "" >&2
    echo "âœ… æ¤œå‡ºå®Œäº†" >&2
}

main "$@"